#########################Docker################
1. Shell :
A shell is an environment or a special user program which provide an interface to user to use operating system services. It executes programs based on the input provided by the user.

2. Kernel :
Kernel is the heart and core of an Operating System that manages operations of computer and hardware. It acts as a bridge between the user and the resources of the system by accessing various computer resources like the CPU, I/O devices and other resources.


##
docker isolation:
Docker uses a technology called namespaces to provide the isolated workspace called the container. When you run a container, Docker creates a set of namespaces for that container. These namespaces provide a layer of isolation.
###Docker namespace
A namespace is basically a Linux feature that ensures OS resources partition in a mutually exclusive manner. This forms the core concept behind containerization as namespaces introduce a layer of isolation amongst the containers. In docker, the namespaces ensure that the containers are portable and they don't affect the underlying host. Examples for namespace types that are currently being supported by Docker – PID, Mount, User, Network, IPC.

##
Docker file
Docker can build images automatically by reading the instructions from a Dockerfile. A Dockerfile is a text document that contains all the commands a user could call on the command line to assemble an image. Using docker build users can create an automated build that executes several command-line instructions in succession.

##
compose
Compose is a tool for defining and running multi-container Docker applications. With Compose, you use a YAML file to configure your application’s services.


###
Docker Image Size - How to Keep It Small?
Use a Smaller Image Base (Alpine)
Use a .dockerignore File.
Utilize the Multi-Stage Builds Feature in Docker.
Avoid Adding Unnecessary Layers to Reduce Docker Image Size.
Beware of Updates and Unnecessary Packages and Dependencies.
Bonus Tip: Caching.

##Docker installation in RHEL
yum update
yum install docker.io
docker version
systemctl status docker
systemctl enable docker
systemctl start docker
docker run hello-world

##Running containers
docker images (shows all the downloaded images  & locally available images in machine)
docker ps (List the running containers OR To check running containers in system)
docker ps -a (List all the containers OR To check running containers in system and were running containers )
docker search ubuntu
docker pull ubuntu
docker run ubuntu
cd /var/lib/docker/containers
ls -lrt 
docker run -it ubuntu /bin/bash (-it to enter in interactive tty mode)
docker run nginx

Note: Docker conatiners are not statefull. Docker Images are blueprint of containers. Once you exit from container, contailer is lost and all the changes also lost.

docker run -it -d ubuntu (to run container in daemon mode)
docker ps
docker attach <container_id> (to SSH or Login to the container)
docker exec -it <container_id> (Login to the container)
docker inspect <container_id> (Fetch info about container)
docker stats <container_id> (Look at the CPU ,Memory and storage, network performance of container)
docker restart <container_id>
docker stop <container_id>
docker start <container_id>
docker rm <container_id>
docker rm -f <container_id> (Force delete of a container when container is running)
docker rename <container_id> <conatiner2>

Note: delete container first and then images otherwise we can get this message: conflict unable to delete <image id>, image is being used <container id>
docker rm <container_id>
docker rmi <image_id>

##creating docker images
docker commit <container_id> <image_name>
docker commit <container_id> apache:1.0
docker run -itd apache:1.0

##Docker volumes:
Docker volumes are file systems mounted on Docker containers to preserve data generated by the running container. 
The volumes are stored on the host, independent of the container life cycle.
This allows users to back up data and share file systems between containers easily.

docker volume create my-vol
docker volume ls
docker volume inspect my-vol
docker volume rm my-vol
docker run -itd --name <container_name> -v my-vol:/data ubuntu:14.04
docker inspect container_id

###########################Docker file->>vi Dockerfile########################
FROM ubuntu

##skip prompt
ARG DEBIAN_FRONTEND=non_interactive

##update packages
RUN apt update; apt dist-upgarde -y

##Install Packages
RUN apt install -y apache2

##Set EntryPoint
ENTRYPOINT apache2ctl -D FOREGROUND

########################END Dockerfile#######################

docker build -t apache:1.0 .


##
What command is used for remove all stopped containers, unused networks, build caches, and dangling images?
docker sytem prune

#######################Docker network######################################################
One of the reasons Docker containers and services are so powerful is that you can connect them together, or connect them to non-Docker workloads. Docker containers and services do not even need to be aware that they are deployed on Docker, or whether their peers are also Docker workloads or not. Whether your Docker hosts run Linux, Windows, or a mix of the two, you can use Docker to manage them in a platform-agnostic way.

Note: Once you launch new container a virtual Ethernet port on docker0 switch gets created 
ip a 
route -n

docker run -p 5001:8080 tomcat:7 (Run a new container with port mapping)
docker port <conatiner_id> (verify the port mapping)
docker network ls (List the docker networks)
docker network inspect bridge (Inspect details about your bridge docker0 & it shows Docker subnet, Conatiner's ip addresses & The Engine automatically creates a Subnet and Gateway to the network. The docker run command automatically adds new containers to this network.)
docker network create --driver=bridge network01 (Create a network network01)
docker network create --driver=bridge network02 (Create a network network02)
docker network ls (List available networks and verify new network is created)
docker run -itd --network=network01 --name=container01 ubuntu:14.04 (Creating new container conatiner01 in the new network network01 created)
docker run -itd --network=network02 --name=container02 ubuntu:14.04 (Creating new container conatiner02 in the new network network02 created)
docker network inspect network01 (Inspect network01--> network01 subnet & container01 ip )
docker network inspect network02 (Inspect network02 -->network02 subnet & container02 ip)
docker network connect network02 conatiner01 (Attach your container01 to netowrk02)
docker exec -it container01 /bin/bash
ping <container02_ip present in network02>

##Creating network with desired cidr
docker network create --driver=bridge --subnet=10.0.1.0/24 --gateway=10.0.1.1 network04
docker network inspect network04
docker run --network=network04 --ip 10.0.1.4 -itd --name=container05 ubuntu:14.04
docker exec -it container05 /bin/bash

##How publishing ports works
By default, if you use the docker run or docker create command to run or create a container, they do not make any Docker’s ports accessible by services in the outside world.
So, while it’s possible for your Docker containers to connect to the outside world without making any changes to your code, it’s not possible for the outside world to connect to your Docker containers.
If you want to override this default behavior, you can use either the -P or the -p flag in your Docker run string. 
Publishing ports produce a firewall rule that binds a container port to a port on the Docker host, ensuring the ports are accessible to any client that can communicate with the host. 
It’s what makes a port accessible to Docker containers that are not connected to the container’s network, or services that are outside of your Docker environment.
################End Docker networking#################

can we use Git/Bitbucket repos as DockerHub?
what is debian & fedora?
what is entrypoint in docker?


##docker compose
##Install the required Packages for Docker Compose
yum install epel-release -y
yum install -y python-pip
pip install docker-compose
yum upgrade python*
mkdir my-wordpress
cd my-wordpress
vi docker-compose.yaml
Run the docker-compose command and you pwd should be /root/my-wordpress
docker-compose up -d 
docker-compose ps (Run the docker-compose ps command to check the containers)

##############vi docker-compose.yaml######################
version: '2'
services:
   db:
     image: mysql:5.7
     volumes:
       - db_data:/var/lib/mysql
     restart: always
     environment:
       MYSQL_ROOT_PASSWORD: wordpress
       MYSQL_DATABASE: wordpress
       MYSQL_USER: wordpress
       MYSQL_PASSWORD: wordpress

   wordpress:
     depends_on:
       - db
     image: wordpress:latest
     ports:
       - "8000:80"
     restart: always
     environment:
       WORDPRESS_DB_HOST: db:3306
       WORDPRESS_DB_PASSWORD: wordpress
volumes:
    db_data:
##################End compose file########
